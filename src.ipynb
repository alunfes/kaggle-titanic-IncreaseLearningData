import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import xgboost as xgb
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import random

def preprocess(df):
    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())
    df['Age'] = df['Age'].fillna(df['Age'].mean())
    df['Embarked'] = df['Embarked'].fillna('Unknown')
    df['Embarked'] = df['Embarked'].map({'S':0, 'C':1, 'Q':2, 'Unknown':3}).astype(int)
    df['Sex'] = df['Sex'].apply(lambda x: 1 if x =='male' else 0)
    df['Cabin'] = df['Cabin'].fillna(0)
    df['Cabin'] = df['Cabin'].apply(lambda x: 1 if x !=0 else 0)
    df = df.drop(['Name','PassengerId','Ticket'], axis = 1)
    return df

#split original train data to train - test data to use for pretest
def splitToTrainAndTest(df):
    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)
    df_s = df.sample(frac=1)
    train_end = int(np.floor(0.8*len(df_s)))
    train = df_s.iloc[:train_end]
    test =df_s.iloc[train_end+1:len(df_s)]
    return train, test



def train(train_x, train_y):
    print('training data description')
    print('train_x', train_x.shape)
    print('train_y', train_y.shape)
    train = xgb.DMatrix(train_x, label=train_y)
    param = {'max_depth':5, 'max_leaves':48, 'num_class':1, 'eta':0.1, 
             'learning_rate':0.3, 'objective':'binary:logistic','silent':True}
    num_round =10
    bst = xgb.train(param, train, num_round)
    return bst

def trainClassifier(train_x, train_y):
    print('training data description')
    print('train_x', train_x.shape)
    print('train_y', train_y.shape)
    clf = xgb.XGBClassifier(random_state=42,max_depth=7,min_child_weight=1,learning_rate=0.1,
                           n_estimators=500,silent=True,objective='binary:logistic',
                           gamma=0,max_delta_step=0,subsample=1,
                           colsample_bytree=1,colsample_bylevel=1,
                           reg_alpha=0,reg_lambda=0,
                           scale_pos_weight=1,seed=1,
                           missing=None)
    clf.fit(train_x,train_y)
    return clf


def outValConverter(prediction):
    con_pre = []
    for el in prediction:
        if el > 0.5:
            con_pre.append(1)
        else:
            con_pre.append(0)
    return con_pre

def generateSubmission(prediction_pd):
    df_out = pd.read_csv("../input/test.csv",header=0)
    df_out = df_out['PassengerId']
    out = prediction_pd["Survived"]
    submission = pd.DataFrame({"PassengerId": df_out, "Survived": out})
    submission.to_csv('gender_submission.csv', index=False)
    print(submission)


    #generate new data which is classified as 0 or 1 using a trained clf
    #return pd concat(train_x + train_y, newd)
def increaseTrainingData(train_x, train_y, clf, num_increase):
    num = 0
    res = pd.concat([train_x, train_y])
    while num < num_increase:
        newd = generateRandomCombinedData(train_x)
        pred = clf.predict(newd)
        print('pred ={}'.format(prd))
        if pred > 0.9:
            newd['Survived'] = 1
        elif pred < 0.1:
            newd['Survived'] = 0
        con_train = pd.concat([train_x, train_y],axis=1)
        res = pd.concat([con_train,newd])
    return res

def increaseTrainingDataBST(train_x, train_y, bst, num_increase):
    num = 0
    res = pd.concat([train_x, train_y], axis=1)
    while num < num_increase:
        newd = generateRandomCombinedData(train_x)
        pred = bst.predict(xgb.DMatrix(newd))
        print('pred = {}, num={}'.format(pred,num))
        if pred > 0.9:
            newd['Survived'] = 1
            res = pd.concat([res,newd])
            num += 1
        elif pred < 0.1:
            newd['Survived'] = 0
            res = pd.concat([res,newd])
            num += 1
    return res.reset_index(drop=True)

def generateRandomCombinedData(train_x: pd.DataFrame):
    num_row = len(train_x)
    num_col = len(train_x.columns)
    newd = []
    for i in range(num_col):
        newd.append(train_x.iat[random.randint(0,num_row-1),i])
    #from IPython.core.debugger import Pdb; Pdb().set_trace()
    newdd = pd.DataFrame(newd).T
    newdd.columns = train_x.columns
    return newdd
    
train_data = pd.read_csv("../input/train.csv", header=0)
test_data = pd.read_csv("../input/test.csv", header=0)
train_data = preprocess(train_data)
train_y = pd.DataFrame(train_data['Survived'],columns=['Survived'])
train_x = train_data.drop(['Survived'], axis=1)


#xgboost
# bst = train(train_x, train_y)
# test_data = preprocess(test_data)
#prediction = bst.predict(xgb.DMatrix(test_data))

#increase data xgboost
bst = train(train_x, train_y)
data = increaseTrainingDataBST(train_x, train_y, bst, 5000)
train_y_increased = data['Survived']
train_x_increased = data.drop(['Survived'], axis = 1)
bst = train(train_x_increased, train_y_increased)
test_data = preprocess(test_data)
prediction = bst.predict(xgb.DMatrix(test_data))

#xgboost classifier
# clf = trainClassifier(train_x, train_y)
# prediction = clf.predict(preprocess(test_data))
# print(prediction)

outputs = pd.DataFrame(outValConverter(prediction), columns=['Survived'])
generateSubmission(outputs)
print('Completed!')
